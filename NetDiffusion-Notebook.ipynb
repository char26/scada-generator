{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file is a snapshot of our struggles with NetDiffusion. Some cells contain some AI-assisted code. This file does not capture the evolution over time, but simply the final state."
      ],
      "metadata": {
        "id": "mntxVt2lkBht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/MyDrive/SCADA_NetDiff/\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGN7BxKMrVEO",
        "outputId": "9f100525-5ac4-44c5-a1c7-fff4d201ad8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data/ color_corrected_generated_traffic_images/ generated_nprint/ generated_traffic_images/ nprint_traffic_images/ nprint_traffic/ pcaps/ replayable_generated_nprints/ replayable_generated_pcaps/ trained-sd3-lora-miniature/ wandb/ sample_embeddings.parquet nprint-1.2.1/ scripts/ nprint-1.2.1.tar.gz* payload_mask.png column_order_*.txt conditioning*"
      ],
      "metadata": {
        "id": "RSWq8MnLTlHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nJLZqNAcUPV",
        "outputId": "21132277-8466-4a2d-bf0f-aa695b0a459d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYdpJJRacUPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d6cc07-98fa-4ced-88e7-ccc97e5eaab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U \\\n",
        "    transformers \\\n",
        "    accelerate \\\n",
        "    wandb \\\n",
        "    bitsandbytes \\\n",
        "    peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7-1DQzzcUPV",
        "outputId": "fe324c21-5a74-4713-d381-21501a8ffb22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Collecting controlnet_aux\n",
            "  Downloading controlnet_aux-0.0.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting scapy\n",
            "  Downloading scapy-2.6.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.9.0+cu126)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.5.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from controlnet_aux) (8.7.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from controlnet_aux) (0.36.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from controlnet_aux) (1.16.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from controlnet_aux) (4.12.0.88)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from controlnet_aux) (0.8.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from controlnet_aux) (1.0.22)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from controlnet_aux) (0.25.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->controlnet_aux) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->controlnet_aux) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->controlnet_aux) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->controlnet_aux) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.11.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->controlnet_aux) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->controlnet_aux) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->controlnet_aux) (0.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->controlnet_aux) (0.7.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n",
            "Downloading controlnet_aux-0.0.10-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scapy-2.6.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scapy, controlnet_aux\n",
            "Successfully installed controlnet_aux-0.0.10 scapy-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas torchvision pyarrow sentencepiece controlnet_aux scapy gdown opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/noise-lab/NetDiffusion.git\n",
        "!mv NetDiffusion/scripts scripts && rm -rf NetDiffusion/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCOyht-couf5",
        "outputId": "6bbc10c9-efd1-4b8e-b2e1-ffcfc2d62c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NetDiffusion'...\n",
            "remote: Enumerating objects: 179, done.\u001b[K\n",
            "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 179 (delta 81), reused 123 (delta 49), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (179/179), 5.00 MiB | 21.07 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmnvsO9gcUPW"
      },
      "source": [
        "As SD3 is gated, before using it with diffusers you first need to go to the Stable Diffusion 3 Medium Hugging Face page, fill in the form and accept the gate. Once you are in, you need to log in so that your system knows you’ve accepted the gate. Use the command below to log in:\n",
        "#Ignore if already logged in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVDMaLi6cUPW"
      },
      "source": [
        "## Hugging Face Authentication\n",
        "\n",
        "As SD3 is gated, you need to:\n",
        "1. Go to the [Stable Diffusion 3 Medium Hugging Face page](https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers)\n",
        "2. Fill in the form and accept the gate\n",
        "3. Log in to authenticate your access\n",
        "\n",
        "Check if you're already logged in first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MBuRzmacUPW",
        "outputId": "3a30f20b-4167-4329-e3cd-98230d61c06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "/usr/lib/python3.12/getpass.py:91: GetPassWarning: Can not control echo on the terminal.\n",
            "  passwd = fallback_getpass(prompt, stream)\n",
            "Warning: Password input may be echoed.\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Token is valid (permission: write).\n",
            "The token `scada-generator` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `scada-generator`\n"
          ]
        }
      ],
      "source": [
        "# If not logged in, run this command and enter your token when prompted\n",
        "!hf auth login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libpcap-dev\n",
        "!wget https://github.com/nprint/nprint/releases/download/v1.2.1/nprint-1.2.1.tar.gz\n",
        "!tar -xvf nprint-1.2.1.tar.gz\n",
        "!cd nprint-1.2.1 && ./configure && make && make install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDudgF1jeCZx",
        "outputId": "24670de5-e0cc-4a85-f4bb-c2aadc114d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libdbus-1-dev libpcap0.8 libpcap0.8-dev\n",
            "The following NEW packages will be installed:\n",
            "  libdbus-1-dev libpcap-dev libpcap0.8 libpcap0.8-dev\n",
            "0 upgraded, 4 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 607 kB of archives.\n",
            "After this operation, 2,238 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcap0.8 amd64 1.10.1-4ubuntu1.22.04.1 [145 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-dev amd64 1.12.20-2ubuntu4.1 [188 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcap0.8-dev amd64 1.10.1-4ubuntu1.22.04.1 [270 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcap-dev amd64 1.10.1-4ubuntu1.22.04.1 [3,326 B]\n",
            "Fetched 607 kB in 2s (289 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpcap0.8:amd64.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../libpcap0.8_1.10.1-4ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libpcap0.8:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Selecting previously unselected package libdbus-1-dev:amd64.\n",
            "Preparing to unpack .../libdbus-1-dev_1.12.20-2ubuntu4.1_amd64.deb ...\n",
            "Unpacking libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Selecting previously unselected package libpcap0.8-dev:amd64.\n",
            "Preparing to unpack .../libpcap0.8-dev_1.10.1-4ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libpcap0.8-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Selecting previously unselected package libpcap-dev:amd64.\n",
            "Preparing to unpack .../libpcap-dev_1.10.1-4ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libpcap-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Setting up libpcap0.8:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Setting up libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Setting up libpcap0.8-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Setting up libpcap-dev:amd64 (1.10.1-4ubuntu1.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "--2025-12-04 05:58:15--  https://github.com/nprint/nprint/releases/download/v1.2.1/nprint-1.2.1.tar.gz\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/285380967/f455ab38-1c22-4463-9a69-ed07fbc8e3ed?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-04T06%3A41%3A10Z&rscd=attachment%3B+filename%3Dnprint-1.2.1.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-04T05%3A40%3A39Z&ske=2025-12-04T06%3A41%3A10Z&sks=b&skv=2018-11-09&sig=um0mobTmUGOFn4%2BrJX%2ByteKUd9xt1VwuMheiSoTDj8w%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDgyODE5NSwibmJmIjoxNzY0ODI3ODk1LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._Qbq4YJAHYYO-D_XeXbJ7t4AcxR61YPe0BvbT5_qa7I&response-content-disposition=attachment%3B%20filename%3Dnprint-1.2.1.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-04 05:58:16--  https://release-assets.githubusercontent.com/github-production-release-asset/285380967/f455ab38-1c22-4463-9a69-ed07fbc8e3ed?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-04T06%3A41%3A10Z&rscd=attachment%3B+filename%3Dnprint-1.2.1.tar.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-04T05%3A40%3A39Z&ske=2025-12-04T06%3A41%3A10Z&sks=b&skv=2018-11-09&sig=um0mobTmUGOFn4%2BrJX%2ByteKUd9xt1VwuMheiSoTDj8w%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDgyODE5NSwibmJmIjoxNzY0ODI3ODk1LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ._Qbq4YJAHYYO-D_XeXbJ7t4AcxR61YPe0BvbT5_qa7I&response-content-disposition=attachment%3B%20filename%3Dnprint-1.2.1.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 125700 (123K) [application/octet-stream]\n",
            "Saving to: ‘nprint-1.2.1.tar.gz’\n",
            "\n",
            "nprint-1.2.1.tar.gz 100%[===================>] 122.75K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-12-04 05:58:16 (107 MB/s) - ‘nprint-1.2.1.tar.gz’ saved [125700/125700]\n",
            "\n",
            "nprint-1.2.1/\n",
            "nprint-1.2.1/src/\n",
            "nprint-1.2.1/src/nprint.cpp\n",
            "nprint-1.2.1/src/io/\n",
            "nprint-1.2.1/src/io/file_writer.cpp\n",
            "nprint-1.2.1/src/io/stringfile_parser.cpp\n",
            "nprint-1.2.1/src/io/pcap_parser.cpp\n",
            "nprint-1.2.1/src/io/file_parser.cpp\n",
            "nprint-1.2.1/src/io/nprint_parser.cpp\n",
            "nprint-1.2.1/src/stats.cpp\n",
            "nprint-1.2.1/src/conf.cpp\n",
            "nprint-1.2.1/src/packet/\n",
            "nprint-1.2.1/src/packet/icmp_header.cpp\n",
            "nprint-1.2.1/src/packet/tcp_header.cpp\n",
            "nprint-1.2.1/src/packet/ipv4_header.cpp\n",
            "nprint-1.2.1/src/packet/superpacket.cpp\n",
            "nprint-1.2.1/src/packet/udp_header.cpp\n",
            "nprint-1.2.1/src/packet/wlan_header.cpp\n",
            "nprint-1.2.1/src/packet/radiotap_header.cpp\n",
            "nprint-1.2.1/src/packet/payload.cpp\n",
            "nprint-1.2.1/src/packet/packet_header.cpp\n",
            "nprint-1.2.1/src/packet/ethernet_header.cpp\n",
            "nprint-1.2.1/src/packet/ipv6_header.cpp\n",
            "nprint-1.2.1/Makefile.in\n",
            "nprint-1.2.1/configure\n",
            "nprint-1.2.1/include/\n",
            "nprint-1.2.1/include/conf.hpp\n",
            "nprint-1.2.1/include/io/\n",
            "nprint-1.2.1/include/io/file_parser.hpp\n",
            "nprint-1.2.1/include/io/nprint_parser.hpp\n",
            "nprint-1.2.1/include/io/stringfile_parser.hpp\n",
            "nprint-1.2.1/include/io/pcap_parser.hpp\n",
            "nprint-1.2.1/include/io/file_writer.hpp\n",
            "nprint-1.2.1/include/stats.hpp\n",
            "nprint-1.2.1/include/packet/\n",
            "nprint-1.2.1/include/packet/ipv6_header.hpp\n",
            "nprint-1.2.1/include/packet/udp_header.hpp\n",
            "nprint-1.2.1/include/packet/icmp_header.hpp\n",
            "nprint-1.2.1/include/packet/wlan_header.hpp\n",
            "nprint-1.2.1/include/packet/tcp_header.hpp\n",
            "nprint-1.2.1/include/packet/packet_header.hpp\n",
            "nprint-1.2.1/include/packet/superpacket.hpp\n",
            "nprint-1.2.1/include/packet/ethernet_header.hpp\n",
            "nprint-1.2.1/include/packet/radiotap_header.hpp\n",
            "nprint-1.2.1/include/packet/ipv4_header.hpp\n",
            "nprint-1.2.1/include/packet/payload.hpp\n",
            "nprint-1.2.1/config.h.in\n",
            "nprint-1.2.1/Makefile.am\n",
            "nprint-1.2.1/build-aux/\n",
            "nprint-1.2.1/build-aux/depcomp\n",
            "nprint-1.2.1/build-aux/compile\n",
            "nprint-1.2.1/build-aux/config.sub\n",
            "nprint-1.2.1/build-aux/config.guess\n",
            "nprint-1.2.1/build-aux/missing\n",
            "nprint-1.2.1/build-aux/install-sh\n",
            "nprint-1.2.1/aclocal.m4\n",
            "nprint-1.2.1/configure.ac\n",
            "checking for g++... g++\n",
            "checking whether the C++ compiler works... yes\n",
            "checking for C++ compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking for gcc... gcc\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking whether gcc understands -c and -o together... yes\n",
            "checking for pcap_loop in -lpcap... yes\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /usr/bin/grep\n",
            "checking for egrep... /usr/bin/grep -E\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking arpa/inet.h usability... yes\n",
            "checking arpa/inet.h presence... yes\n",
            "checking for arpa/inet.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdbool.h that conforms to C99... yes\n",
            "checking for _Bool... yes\n",
            "checking for int32_t... yes\n",
            "checking for int64_t... yes\n",
            "checking for int8_t... yes\n",
            "checking for size_t... yes\n",
            "checking for uint16_t... yes\n",
            "checking for uint32_t... yes\n",
            "checking for uint64_t... yes\n",
            "checking for uint8_t... yes\n",
            "checking for inet_ntoa... yes\n",
            "./configure: line 4206: WRAPPER_LDFLAGS: command not found\n",
            "./configure: line 4207: WRAPPER_CPPFLAGS: command not found\n",
            "checking build system type... x86_64-pc-linux-gnu\n",
            "checking host system type... x86_64-pc-linux-gnu\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports the include directive... yes (GNU style)\n",
            "checking whether make supports nested variables... yes\n",
            "checking dependency style of gcc... gcc3\n",
            "checking dependency style of g++... gcc3\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating config.h\n",
            "config.status: executing depfiles commands\n",
            "make  all-am\n",
            "make[1]: Entering directory '/content/nprint-1.2.1'\n",
            "depbase=`echo src/conf.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/conf.o -MD -MP -MF $depbase.Tpo -c -o src/conf.o src/conf.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/nprint.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/nprint.o -MD -MP -MF $depbase.Tpo -c -o src/nprint.o src/nprint.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/io/file_parser.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/io/file_parser.o -MD -MP -MF $depbase.Tpo -c -o src/io/file_parser.o src/io/file_parser.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/io/file_writer.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/io/file_writer.o -MD -MP -MF $depbase.Tpo -c -o src/io/file_writer.o src/io/file_writer.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/icmp_header.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/icmp_header.o -MD -MP -MF $depbase.Tpo -c -o src/packet/icmp_header.o src/packet/icmp_header.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/ipv4_header.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/ipv4_header.o -MD -MP -MF $depbase.Tpo -c -o src/packet/ipv4_header.o src/packet/ipv4_header.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/ipv6_header.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/ipv6_header.o -MD -MP -MF $depbase.Tpo -c -o src/packet/ipv6_header.o src/packet/ipv6_header.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/packet_header.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/packet_header.o -MD -MP -MF $depbase.Tpo -c -o src/packet/packet_header.o src/packet/packet_header.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/payload.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/payload.o -MD -MP -MF $depbase.Tpo -c -o src/packet/payload.o src/packet/payload.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/io/pcap_parser.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/io/pcap_parser.o -MD -MP -MF $depbase.Tpo -c -o src/io/pcap_parser.o src/io/pcap_parser.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/io/stringfile_parser.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/io/stringfile_parser.o -MD -MP -MF $depbase.Tpo -c -o src/io/stringfile_parser.o src/io/stringfile_parser.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/superpacket.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/superpacket.o -MD -MP -MF $depbase.Tpo -c -o src/packet/superpacket.o src/packet/superpacket.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/tcp_header.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/tcp_header.o -MD -MP -MF $depbase.Tpo -c -o src/packet/tcp_header.o src/packet/tcp_header.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/udp_header.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/udp_header.o -MD -MP -MF $depbase.Tpo -c -o src/packet/udp_header.o src/packet/udp_header.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/io/nprint_parser.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/io/nprint_parser.o -MD -MP -MF $depbase.Tpo -c -o src/io/nprint_parser.o src/io/nprint_parser.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/ethernet_header.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/ethernet_header.o -MD -MP -MF $depbase.Tpo -c -o src/packet/ethernet_header.o src/packet/ethernet_header.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/wlan_header.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/wlan_header.o -MD -MP -MF $depbase.Tpo -c -o src/packet/wlan_header.o src/packet/wlan_header.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/packet/radiotap_header.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/packet/radiotap_header.o -MD -MP -MF $depbase.Tpo -c -o src/packet/radiotap_header.o src/packet/radiotap_header.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "depbase=`echo src/stats.o | sed 's|[^/]*$|.deps/&|;s|\\.o$||'`;\\\n",
            "g++ -DHAVE_CONFIG_H -I.  -Iinclude/ -Iinclude/io/ -Iinclude/packet/ -pedantic -Wall -std=gnu++11    -g -O2 -MT src/stats.o -MD -MP -MF $depbase.Tpo -c -o src/stats.o src/stats.cpp &&\\\n",
            "mv -f $depbase.Tpo $depbase.Po\n",
            "g++  -g -O2   -o nprint src/conf.o src/nprint.o src/io/file_parser.o src/io/file_writer.o src/packet/icmp_header.o src/packet/ipv4_header.o src/packet/ipv6_header.o src/packet/packet_header.o src/packet/payload.o src/io/pcap_parser.o src/io/stringfile_parser.o src/packet/superpacket.o src/packet/tcp_header.o src/packet/udp_header.o src/io/nprint_parser.o src/packet/ethernet_header.o src/packet/wlan_header.o src/packet/radiotap_header.o src/stats.o  -lpcap \n",
            "make[1]: Leaving directory '/content/nprint-1.2.1'\n",
            "make[1]: Entering directory '/content/nprint-1.2.1'\n",
            " /usr/bin/mkdir -p '/usr/local/bin'\n",
            "  /usr/bin/install -c nprint '/usr/local/bin'\n",
            "make[1]: Nothing to be done for 'install-data-am'.\n",
            "make[1]: Leaving directory '/content/nprint-1.2.1'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHANGE DOWNLOADED PCAP BELOW"
      ],
      "metadata": {
        "id": "pIRXthA1R2X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pcaps\n",
        "!mkdir nprint_traffic\n",
        "# Modbus messaging\n",
        "!cd pcaps && wget \"https://drive.google.com/uc?export=download&id=1rePKAWeVPMIN21WPcF34g3WSfzLi9mCm\" -O input_traces.pcapng\n",
        "\n",
        "# SEL\n",
        "# REDACTED SEL LINK DUE TO CLOSED-SOURCE DATASET\n",
        "\n",
        "# !cd pcaps && wget https://github.com/antoine-lemay/Modbus_dataset/raw/master/channel_2d_3s.zip\n",
        "# !cd pcaps && unzip channel_2d_3s.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX3E3sIle_VF",
        "outputId": "5e80f14b-1c7a-485d-f00d-f5dd97735a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-04 05:58:36--  https://drive.google.com/uc?export=download&id=1VwIHDyfEU-NFjTTj-gZ7TPYoezoqN2br\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.10.139, 142.251.10.100, 142.251.10.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.10.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1VwIHDyfEU-NFjTTj-gZ7TPYoezoqN2br&export=download [following]\n",
            "--2025-12-04 05:58:36--  https://drive.usercontent.google.com/download?id=1VwIHDyfEU-NFjTTj-gZ7TPYoezoqN2br&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.253.118.132, 2404:6800:4003:c05::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.253.118.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1907721 (1.8M) [application/octet-stream]\n",
            "Saving to: ‘input_traces.pcapng’\n",
            "\n",
            "input_traces.pcapng 100%[===================>]   1.82M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-12-04 05:58:38 (178 MB/s) - ‘input_traces.pcapng’ saved [1907721/1907721]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !nprint -F -1 -P pcaps/input_traces.pcapng -4 -i -6 -t -u -p 0 -c 1024 -W nprint_traffic/modbus.nprint\n",
        "# p = 8, include 8 payload bytes to stay divisible by 64\n",
        "!nprint -P pcaps/input_traces.pcapng -4 -6 -t -u -i -p 8 -c 1024 -W nprint_traffic/modbus.nprint"
      ],
      "metadata": {
        "id": "cqjaV-WyfXiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_624-n1AcUPX"
      },
      "source": [
        "## Convert nPrint to PNG Images\n",
        "\n",
        "This script transforms `.nprint` files—tabular feature representations of network packets—into fixed-size PNG images that can be used as input for SD fine-tuning.\n",
        "\n",
        "**Input:** `.nprint` files generated from packet captures (PCAPs) using the nPrint tool. Each file is a CSV-like matrix where each row represents a single packet and columns correspond to extracted features.\n",
        "\n",
        "**Preprocessing:**\n",
        "- Drops IP address-related columns to avoid injecting identifiable or non-generalizable information into the model\n",
        "- Maps integer values in the remaining columns to RGBA color tuples to visualize numeric features as colored pixels\n",
        "\n",
        "**Padding:** Pads each image to a uniform height (default 1024) using a solid background to ensure model input consistency across varying packet counts.\n",
        "\n",
        "**Output:** Saves a PNG file for each `.nprint` file, preserving the packet structure as a vertically stacked color-coded image (rows = packets, cols = features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd-F7_6LcUPX",
        "outputId": "c82aeab2-0f80-4b35-ad30-0f870b91f18d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing modbus.nprint\n",
            "/content/./scripts/nprint_to_png.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  np_df = np.array(df.applymap(np.array).to_numpy().tolist())\n",
            "/content/./scripts/nprint_to_png.py:29: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(np_img, 'RGBA')\n"
          ]
        }
      ],
      "source": [
        "!python ./scripts/nprint_to_png.py -i ./nprint_traffic/ -o ./nprint_traffic_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": true,
        "id": "rtyjLP27cUPX"
      },
      "source": [
        "## Compute Embeddings\n",
        "\n",
        "Generates text prompt embeddings via a Stable Diffusion 3 pipeline and T5 text encoder. Maps each local PNG image to a unique SHA-256 hash and associates it with the computed embeddings. Stores the resulting image-hash-to-embedding data in a .parquet file for further processing.\n",
        "\n",
        "Here we are using the default instance prompt \"pixelated network data for type-0 application traffic\". You can configure this by referring to the compute_embeddings.py script for details on other supported arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG127Lh0cUPX",
        "outputId": "372ec1f5-1943-4822-9300-225f24873642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-04 05:58:54.200425: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-04 05:58:54.217913: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764827934.239100    2168 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764827934.245768    2168 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764827934.261966    2168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764827934.261994    2168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764827934.261997    2168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764827934.261999    2168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-04 05:58:54.266799: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "config.json: 100% 740/740 [00:00<00:00, 5.29MB/s]\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "model.safetensors.index.json: 100% 19.9k/19.9k [00:00<00:00, 75.3MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "text_encoder_3/model-00001-of-00002.safe(…):   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):   0% 0.00/4.53G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):   0% 12.2M/4.99G [00:02<16:04, 5.17MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):   0% 285k/4.53G [00:02<10:50:04, 116kB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):   8% 403M/4.99G [00:03<00:27, 168MB/s]  \u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  19% 954M/4.99G [00:03<00:09, 432MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  21% 1.07G/4.99G [00:03<00:10, 378MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):   5% 221M/4.53G [00:03<00:55, 78.2MB/s]  \u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  24% 1.17G/4.99G [00:04<00:10, 367MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):   6% 288M/4.53G [00:04<00:50, 84.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  10% 470M/4.53G [00:04<00:25, 162MB/s] \u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  13% 604M/4.53G [00:06<00:38, 101MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  26% 1.31G/4.99G [00:07<00:27, 135MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  19% 872M/4.53G [00:06<00:19, 187MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  21% 958M/4.53G [00:07<00:22, 157MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  29% 1.43G/4.99G [00:08<00:31, 114MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  23% 1.03G/4.53G [00:08<00:28, 123MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  31% 1.56G/4.99G [00:09<00:29, 115MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  33% 1.63G/4.99G [00:10<00:29, 114MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  35% 1.76G/4.99G [00:11<00:25, 125MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  38% 1.88G/4.99G [00:11<00:20, 148MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  24% 1.11G/4.53G [00:11<00:44, 76.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  26% 1.18G/4.53G [00:12<00:41, 81.2MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  39% 1.95G/4.99G [00:12<00:25, 120MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  27% 1.24G/4.53G [00:12<00:34, 95.0MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  40% 2.01G/4.99G [00:12<00:21, 140MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  30% 1.38G/4.53G [00:13<00:26, 119MB/s] \u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  32% 1.44G/4.53G [00:13<00:23, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  35% 1.58G/4.53G [00:16<00:36, 80.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  36% 1.65G/4.53G [00:16<00:31, 92.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  38% 1.71G/4.53G [00:16<00:24, 114MB/s] \u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  42% 2.08G/4.99G [00:17<00:58, 49.4MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  39% 1.76G/4.53G [00:16<00:23, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  40% 1.83G/4.53G [00:17<00:23, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  42% 1.91G/4.53G [00:20<00:47, 54.8MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  43% 2.16G/4.99G [00:21<01:19, 35.5MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  44% 1.98G/4.53G [00:22<00:48, 52.5MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  45% 2.23G/4.99G [00:22<01:12, 38.0MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  45% 2.25G/4.99G [00:22<01:08, 40.3MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  46% 2.32G/4.99G [00:22<00:48, 54.9MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  48% 2.38G/4.99G [00:23<00:34, 75.4MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  48% 2.18G/4.53G [00:22<00:24, 94.0MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  50% 2.52G/4.99G [00:23<00:18, 135MB/s] \u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  52% 2.59G/4.99G [00:23<00:15, 157MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  54% 2.72G/4.99G [00:23<00:11, 200MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  50% 2.25G/4.53G [00:25<00:38, 58.8MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  56% 2.79G/4.99G [00:26<00:25, 87.5MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  53% 2.38G/4.53G [00:25<00:23, 90.3MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  58% 2.92G/4.99G [00:26<00:15, 136MB/s] \u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  54% 2.45G/4.53G [00:25<00:19, 108MB/s] \u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  60% 2.99G/4.99G [00:26<00:12, 165MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  56% 2.55G/4.53G [00:26<00:18, 108MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  63% 3.12G/4.99G [00:27<00:13, 134MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  58% 2.62G/4.53G [00:27<00:20, 91.3MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  64% 3.20G/4.99G [00:28<00:15, 112MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  59% 2.69G/4.53G [00:28<00:18, 102MB/s] \u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  65% 3.27G/4.99G [00:29<00:15, 110MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  61% 2.75G/4.53G [00:29<00:20, 87.5MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  67% 3.34G/4.99G [00:30<00:17, 97.0MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  62% 2.82G/4.53G [00:30<00:19, 89.7MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  68% 3.40G/4.99G [00:30<00:14, 109MB/s] \u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  64% 2.89G/4.53G [00:30<00:15, 108MB/s] \u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  69% 3.46G/4.99G [00:30<00:12, 126MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  71% 3.52G/4.99G [00:31<00:10, 138MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  65% 2.95G/4.53G [00:31<00:14, 106MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  72% 3.59G/4.99G [00:31<00:10, 135MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  67% 3.02G/4.53G [00:32<00:16, 90.8MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  75% 3.72G/4.99G [00:32<00:09, 139MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  68% 3.09G/4.53G [00:32<00:12, 111MB/s] \u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  70% 3.16G/4.53G [00:35<00:27, 50.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  71% 3.22G/4.53G [00:35<00:19, 66.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  73% 3.29G/4.53G [00:35<00:14, 87.0MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  76% 3.79G/4.99G [00:36<00:23, 50.9MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  74% 3.36G/4.53G [00:36<00:12, 95.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  75% 3.39G/4.53G [00:37<00:16, 71.0MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  77% 3.85G/4.99G [00:39<00:27, 40.8MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  76% 3.46G/4.53G [00:39<00:21, 49.6MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  79% 3.92G/4.99G [00:40<00:23, 45.1MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  78% 3.52G/4.53G [00:41<00:20, 48.7MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  80% 3.99G/4.99G [00:41<00:21, 46.4MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  81% 4.06G/4.99G [00:41<00:15, 61.4MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  81% 3.66G/4.53G [00:41<00:10, 85.8MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  83% 4.12G/4.99G [00:42<00:11, 74.5MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  82% 3.73G/4.53G [00:41<00:08, 93.1MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  87% 4.32G/4.99G [00:42<00:04, 151MB/s] \u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  84% 3.79G/4.53G [00:42<00:07, 100MB/s] \u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  88% 4.39G/4.99G [00:45<00:08, 73.9MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  85% 3.86G/4.53G [00:44<00:10, 61.2MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  89% 4.46G/4.99G [00:45<00:05, 92.0MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  90% 4.06G/4.53G [00:44<00:03, 124MB/s] \u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  91% 4.52G/4.99G [00:45<00:04, 114MB/s] \u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  92% 4.59G/4.99G [00:45<00:03, 128MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  93% 4.19G/4.53G [00:45<00:02, 128MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  93% 4.66G/4.99G [00:46<00:03, 96.8MB/s]\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  96% 4.79G/4.99G [00:47<00:01, 114MB/s] \u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  94% 4.26G/4.53G [00:47<00:02, 94.1MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  97% 4.86G/4.99G [00:48<00:01, 112MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  96% 4.33G/4.53G [00:48<00:02, 85.3MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…):  99% 4.93G/4.99G [00:49<00:00, 99.9MB/s]\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  97% 4.40G/4.53G [00:49<00:01, 88.2MB/s]\u001b[A\u001b[A\n",
            "text_encoder_3/model-00001-of-00002.safe(…): 100% 4.99G/4.99G [00:49<00:00, 101MB/s]\n",
            "Fetching 2 files:  50% 1/2 [00:50<00:50, 50.16s/it]\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…):  99% 4.46G/4.53G [00:49<00:00, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "text_encoder_3/model-00002-of-00002.safe(…): 100% 4.53G/4.53G [00:49<00:00, 91.0MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:50<00:00, 25.39s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:09<00:00,  4.68s/it]\n",
            "model_index.json: 100% 706/706 [00:00<00:00, 6.47MB/s]\n",
            "Fetching 18 files:   0% 0/18 [00:00<?, ?it/s]\n",
            "text_encoder/model.safetensors:   0% 0.00/247M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "config.json: 100% 570/570 [00:00<00:00, 5.05MB/s]\n",
            "\n",
            "\n",
            "scheduler_config.json: 100% 141/141 [00:00<00:00, 629kB/s]\n",
            "\n",
            "\n",
            "special_tokens_map.json: 100% 588/588 [00:00<00:00, 6.31MB/s]\n",
            "\n",
            "\n",
            "config.json: 100% 574/574 [00:00<00:00, 6.82MB/s]\n",
            "Fetching 18 files:  11% 2/18 [00:00<00:03,  4.05it/s]\n",
            "\n",
            "text_encoder_2/model.safetensors:   0% 0.00/1.39G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 705/705 [00:00<00:00, 8.55MB/s]\n",
            "\n",
            "\n",
            "\n",
            "merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 1.09MB/s]\n",
            "\n",
            "\n",
            "\n",
            "special_tokens_map.json: 100% 576/576 [00:00<00:00, 4.96MB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 856/856 [00:00<00:00, 8.86MB/s]\n",
            "\n",
            "text_encoder/model.safetensors:   0% 1.22M/247M [00:00<02:20, 1.75MB/s]\u001b[A\n",
            "\n",
            "\n",
            "vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_3/spiece.model:   0% 0.00/792k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "special_tokens_map.json: 100% 2.54k/2.54k [00:00<00:00, 21.6MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 20.6k/20.6k [00:00<00:00, 77.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:   0% 0.00/2.42M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:   0% 334k/1.39G [00:01<1:20:43, 287kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_3/spiece.model: 100% 792k/792k [00:00<00:00, 1.52MB/s]\n",
            "\n",
            "\n",
            "\n",
            "vocab.json: 100% 1.06M/1.06M [00:00<00:00, 1.33MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 100% 2.42M/2.42M [00:00<00:00, 2.64MB/s]\n",
            "\n",
            "\n",
            "text_encoder_2/model.safetensors:   5% 68.1M/1.39G [00:02<00:43, 30.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  19% 258M/1.39G [00:02<00:08, 138MB/s]  \u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  28% 392M/1.39G [00:03<00:07, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  33% 459M/1.39G [00:04<00:07, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  38% 526M/1.39G [00:04<00:06, 129MB/s]\u001b[A\u001b[A\n",
            "text_encoder/model.safetensors:  28% 68.2M/247M [00:05<00:12, 14.0MB/s]\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  43% 593M/1.39G [00:05<00:05, 149MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  48% 660M/1.39G [00:07<00:11, 61.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  57% 794M/1.39G [00:09<00:07, 78.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  61% 853M/1.39G [00:09<00:06, 79.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  81% 1.12G/1.39G [00:09<00:01, 181MB/s]\u001b[A\u001b[A\n",
            "text_encoder/model.safetensors: 100% 247M/247M [00:10<00:00, 23.4MB/s]\n",
            "Fetching 18 files:  22% 4/18 [00:11<00:44,  3.21s/it]\n",
            "\n",
            "text_encoder_2/model.safetensors:  90% 1.26G/1.39G [00:11<00:00, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors:  95% 1.32G/1.39G [00:11<00:00, 173MB/s]\u001b[A\u001b[A\n",
            "\n",
            "text_encoder_2/model.safetensors: 100% 1.39G/1.39G [00:11<00:00, 122MB/s]\n",
            "Fetching 18 files: 100% 18/18 [00:11<00:00,  1.52it/s]\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  5.59it/s]\n",
            "prompt_embeds.shape=torch.Size([1, 154, 4096]), negative_prompt_embeds.shape=torch.Size([1, 154, 4096]), pooled_prompt_embeds.shape=torch.Size([1, 2048]), torch.Size([1, 2048])\n",
            "Max memory allocated: 10.459 GB\n",
            "Data successfully serialized to sample_embeddings.parquet\n"
          ]
        }
      ],
      "source": [
        "!python ./scripts/compute_embeddings.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHp0VNSFcUPX"
      },
      "source": [
        "Compute embeddings:\n",
        "* Generates text prompt embeddings via a Stable Diffusion 3 pipeline and T5 text encoder.\n",
        "* Maps each local PNG image to a unique SHA-256 hash and associates it with the computed embeddings.\n",
        "* Stores the resulting image-hash-to-embedding data in a .parquet file for further processing.\n",
        "* Here we are using the default instance prompt \"pixelated network data for type-0 application traffic\".\n",
        "* But you can configure this. Refer to the compute_embeddings.py script for details on other supported arguments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6qicFrCcUPY"
      },
      "source": [
        "## Train LoRA Adapter on Stable Diffusion 3 (Miniature Setup)\n",
        "\n",
        "This command launches training using `accelerate` with DreamBooth-style LoRA tuning, optimized for quick experimentation or demo runs.\n",
        "\n",
        "**⚠️ Current configuration uses:**\n",
        "- Only 1 training step\n",
        "- Small batch size\n",
        "- No warmup\n",
        "- High learning rate\n",
        "\n",
        "**Intended only for testing or verifying training scripts**, NOT for quality results. For actual training, increase `max_train_steps`, adjust learning rate, and consider enabling full validation and saving checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebtKi7KXcUPY",
        "outputId": "53632817-4d11-4d0d-86ff-903f3b0e2f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-12-04 06:00:43.740360: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-04 06:00:43.758662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764828043.780819    2810 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764828043.787674    2810 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764828043.804224    2810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764828043.804259    2810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764828043.804262    2810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764828043.804265    2810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-04 06:00:43.809296: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "{'invert_sigmas', 'shift_terminal', 'stochastic_sampling', 'max_shift', 'use_karras_sigmas', 'use_exponential_sigmas', 'max_image_seq_len', 'use_beta_sigmas', 'time_shift_type', 'base_shift', 'use_dynamic_shifting', 'base_image_seq_len'} was not found in config. Values will be initialized to default values.\n",
            "config.json: 100% 739/739 [00:00<00:00, 5.17MB/s]\n",
            "vae/diffusion_pytorch_model.safetensors: 100% 168M/168M [00:01<00:00, 102MB/s]\n",
            "{'mid_block_add_attention'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "config.json: 100% 372/372 [00:00<00:00, 3.07MB/s]\n",
            "transformer/diffusion_pytorch_model.safe(…): 100% 4.17G/4.17G [00:10<00:00, 393MB/s]\n",
            "{'qk_norm', 'dual_attention_layers'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing SD3Transformer2DModel.\n",
            "\n",
            "All the weights of SD3Transformer2DModel were initialized from the model checkpoint at stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use SD3Transformer2DModel for predictions without further training.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/offline-run-20251204_060120-znhoyei7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20251204_060120-znhoyei7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20251204_060120-znhoyei7/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/offline-run-20251204_060121-x1m0fde2\u001b[0m\n",
            "Steps:   2% 1/50 [00:02<01:57,  2.39s/it, loss=0.0252, lr=2e-7]{'feature_extractor', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/9 [00:00<?, ?it/s]\u001b[A`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "\n",
            "\n",
            "Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Loading checkpoint shards:  50% 1/2 [00:01<00:01,  1.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.07s/it]\n",
            "Loaded text_encoder_3 as T5EncoderModel from `text_encoder_3` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "\n",
            "Loading pipeline components...:  11% 1/9 [00:02<00:17,  2.19s/it]\u001b[ALoaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "Loaded text_encoder as CLIPTextModelWithProjection from `text_encoder` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "\n",
            "Loading pipeline components...:  33% 3/9 [00:02<00:03,  1.64it/s]\u001b[ALoaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "\n",
            "Loading pipeline components...:  56% 5/9 [00:02<00:01,  3.06it/s]\u001b[AYou set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "Loaded tokenizer_3 as T5TokenizerFast from `tokenizer_3` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "{'invert_sigmas', 'shift_terminal', 'stochastic_sampling', 'max_shift', 'use_karras_sigmas', 'use_exponential_sigmas', 'max_image_seq_len', 'use_beta_sigmas', 'time_shift_type', 'base_shift', 'use_dynamic_shifting', 'base_image_seq_len'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as FlowMatchEulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "\n",
            "Loading pipeline components...:  78% 7/9 [00:02<00:00,  4.18it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "Loading pipeline components...: 100% 9/9 [00:02<00:00,  3.30it/s]\n",
            "Steps: 100% 50/50 [05:23<00:00,  3.50s/it, loss=0.0405, lr=1e-5]   Model weights saved in trained-sd3-lora-miniature/pytorch_lora_weights.safetensors\n",
            "{'feature_extractor', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Loading checkpoint shards:  50% 1/2 [00:01<00:01,  1.11s/it]\u001b[A\u001b[A\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.11s/it]\n",
            "Loaded text_encoder_3 as T5EncoderModel from `text_encoder_3` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "\n",
            "Loading pipeline components...:  11% 1/9 [00:02<00:18,  2.26s/it]\u001b[ALoaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "Loaded text_encoder as CLIPTextModelWithProjection from `text_encoder` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "\n",
            "Loading pipeline components...:  33% 3/9 [00:02<00:03,  1.59it/s]\u001b[ALoaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "Instantiating SD3Transformer2DModel model under default dtype torch.float16.\n",
            "{'qk_norm', 'dual_attention_layers'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing SD3Transformer2DModel.\n",
            "\n",
            "All the weights of SD3Transformer2DModel were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-3-medium-diffusers/snapshots/ea42f8cef0f178587cf766dc8129abd379c90671/transformer.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use SD3Transformer2DModel for predictions without further training.\n",
            "Loaded transformer as SD3Transformer2DModel from `transformer` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "\n",
            "Loading pipeline components...:  56% 5/9 [00:03<00:02,  1.56it/s]\u001b[ALoaded tokenizer_3 as T5TokenizerFast from `tokenizer_3` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "\n",
            "Loading pipeline components...:  67% 6/9 [00:03<00:01,  1.87it/s]\u001b[A{'invert_sigmas', 'shift_terminal', 'stochastic_sampling', 'max_shift', 'use_karras_sigmas', 'use_exponential_sigmas', 'max_image_seq_len', 'use_beta_sigmas', 'time_shift_type', 'base_shift', 'use_dynamic_shifting', 'base_image_seq_len'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as FlowMatchEulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "Instantiating AutoencoderKL model under default dtype torch.float16.\n",
            "{'mid_block_add_attention'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-3-medium-diffusers/snapshots/ea42f8cef0f178587cf766dc8129abd379c90671/vae.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "\n",
            "Loading pipeline components...:  89% 8/9 [00:04<00:00,  2.64it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-3-medium-diffusers.\n",
            "Loading pipeline components...: 100% 9/9 [00:04<00:00,  2.07it/s]\n",
            "Loading transformer.\n",
            "No LoRA keys associated to CLIPTextModelWithProjection found with the prefix='text_encoder'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModelWithProjection related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n",
            "No LoRA keys associated to CLIPTextModelWithProjection found with the prefix='text_encoder_2'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModelWithProjection related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss ▂▂▂▅█▅▅▂▄▃▃▂▂▄▄▃█▂▃▅▂▄▂▅▅▂▅▄▂▁▄▂▆▃▃▁▂▂▆▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   lr ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.04051\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   lr 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20251204_060121-x1m0fde2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20251204_060121-x1m0fde2/logs\u001b[0m\n",
            "Steps: 100% 50/50 [07:54<00:00,  9.50s/it, loss=0.0405, lr=1e-5]\n"
          ]
        }
      ],
      "source": [
        "!export WANDB_MODE=offline && accelerate launch ./scripts/train_dreambooth_lora_sd3_miniature.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-3-medium-diffusers\" \\\n",
        "  --instance_data_dir=\"nprint_traffic_images\" \\\n",
        "  --data_df_path=\"sample_embeddings.parquet\" \\\n",
        "  --output_dir=\"trained-sd3-lora-miniature\" \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --instance_prompt=\"pixelated network data for type-0 application traffic\" \\\n",
        "  --train_batch_size=2 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --use_8bit_adam \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --report_to=\"wandb\" \\\n",
        "  --lr_scheduler=\"cosine\" \\\n",
        "  --lr_warmup_steps=500 \\\n",
        "  --max_train_steps=50 \\\n",
        "  --seed=\"0\" \\\n",
        "  --validation_prompt=\"pixelated network data for type-0 application traffic\" \\\n",
        "  --validation_epochs=100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzq18u2EcUPY"
      },
      "source": [
        "## Inference Pipeline for SD3 + ControlNet + LoRA\n",
        "\n",
        "This cell demonstrates the full generation process:\n",
        "- Loads Stable Diffusion 3 Medium base model\n",
        "- Loads ControlNet (Canny edge-based guidance)\n",
        "- Loads LoRA weights fine-tuned on pixelated network traffic\n",
        "- Applies edge-conditioned generation using a sample input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Create a reference nprint file with dynamic masking.\n",
        "- Columns where ALL values are -1 stay masked\n",
        "- Columns with any non-(-1) values are preserved\n",
        "- Outputs an nprint CSV file for use with reconstruction\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "nprint_path = \"./nprint_traffic/modbus.nprint\"\n",
        "output_nprint_path = \"./conditioning.nprint\"\n",
        "\n",
        "# Load the nprint file\n",
        "df = pd.read_csv(nprint_path)\n",
        "\n",
        "# Drop the src_ip column (it's handled separately in reconstruction)\n",
        "if 'src_ip' in df.columns:\n",
        "    df = df.drop(columns=['src_ip'])\n",
        "\n",
        "print(f\"Original dataframe: {len(df.columns)} columns, {len(df)} rows\")\n",
        "\n",
        "# === DYNAMIC MASKING: Find columns where ALL values are -1 ===\n",
        "cols_to_mask = [col for col in df.columns if (df[col] == -1).all()]\n",
        "cols_to_keep = [col for col in df.columns if col not in cols_to_mask]\n",
        "\n",
        "print(f\"Columns to MASK (all -1s): {len(cols_to_mask)}\")\n",
        "print(f\"Columns to KEEP: {len(cols_to_keep)}\")\n",
        "\n",
        "# Show which protocol groups are being masked\n",
        "protocol_groups = {}\n",
        "for col in cols_to_mask:\n",
        "    prefix = col.split('_')[0]\n",
        "    protocol_groups[prefix] = protocol_groups.get(prefix, 0) + 1\n",
        "\n",
        "print(f\"Masked protocol groups: {protocol_groups}\")\n",
        "\n",
        "# Create the reference nprint (masked columns stay -1, kept columns have data)\n",
        "reference_df = df.copy()\n",
        "\n",
        "# Columns already have correct values - masked ones are already -1\n",
        "# Just verify and save\n",
        "print(f\"✓ Masked {len(cols_to_mask)} columns (all -1)\")\n",
        "print(f\"✓ Preserved {len(cols_to_keep)} columns with data\")\n",
        "\n",
        "# Save the reference nprint\n",
        "reference_df.to_csv(output_nprint_path, index=False)\n",
        "print(f\"✓ Saved reference nprint to {output_nprint_path}\")\n",
        "print(f\"✓ Shape: {reference_df.shape[0]} rows x {reference_df.shape[1]} columns\")\n",
        "\n",
        "# Also save column order for reference\n",
        "with open(\"./column_order.txt\", \"w\") as f:\n",
        "    for col in reference_df.columns:\n",
        "        f.write(f\"{col}\\n\")\n",
        "print(f\"✓ Saved column order to ./column_order.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knfAw6bF-RM_",
        "outputId": "0d0eabe2-84b0-47ee-9580-6e7e8895c3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataframe: 1472 columns, 1024 rows\n",
            "Columns to MASK (all -1s): 992\n",
            "Columns to KEEP: 480\n",
            "Masked protocol groups: {'ipv4': 320, 'ipv6': 320, 'tcp': 224, 'udp': 64, 'icmp': 64}\n",
            "✓ Masked 992 columns (all -1)\n",
            "✓ Preserved 480 columns with data\n",
            "✓ Saved reference nprint to ./conditioning.nprint\n",
            "✓ Shape: 1024 rows x 1472 columns\n",
            "✓ Saved column order to ./column_order.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./scripts/nprint_to_png.py -i . -o ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sjdoe52ZreK",
        "outputId": "91b1f4c9-2ed6-46eb-fa33-2e52a086c574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing conditioning.nprint\n",
            "/content/./scripts/nprint_to_png.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  np_df = np.array(df.applymap(np.array).to_numpy().tolist())\n",
            "/content/./scripts/nprint_to_png.py:29: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(np_img, 'RGBA')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtUtAiRdcUPY"
      },
      "source": [
        "## Post-Generation Processing Pipeline\n",
        "\n",
        "This cell performs a 3-stage transformation of the generated PNG images:\n",
        "\n",
        "1. **Color Augmentation:** Applies standardized color shifts to improve nprint reconstruction accuracy\n",
        "2. **Image-to-nPrint Conversion:** Converts augmented images back into nPrint-compatible feature format using a reference file to maintain consistent structure\n",
        "3. **Heuristic Correction & PCAP Reconstruction:** Reconstructs valid and replayable PCAP files from the diffusion-generated nPrint representation\n",
        "\n",
        "This pipeline enables turning synthetic traffic images back into replayable network traffic for evaluation or simulation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25XStTzicUPZ"
      },
      "source": [
        "Final PCAP files are stored in `replayable_generated_pcaps`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326,
          "referenced_widgets": [
            "e645ed0f64ce4cd194e1aa99c9dc9f44",
            "18ad26219a884a10907170d150171ec6",
            "ef5cb42c1b4c452d8d7c6392f80e0659",
            "eeb58e8bd4c84318882608c564db9e61",
            "32d4cccf904748b1874039e2c959f420",
            "e6fd56e0fda84fd8bbcf4ac026de3301",
            "987bb0b30cb64601a9e0ca6be7ba0b57",
            "aa474b50e6c64037b95f8c131501294d",
            "17dee7f10adc477ab22b296993f7fd4a",
            "19cb046ba457435fb4ef8970e49e775f",
            "1e9fc414fee24446822551019a18a2eb",
            "58ab08fd15a1401a846ad787fb844f63",
            "7227ceb428f2441a8150aea8809f9961",
            "ce4d89b028a346948249d62c84076e8b",
            "15e8a274884742079171fbc037042401",
            "d74f542ae52f4b7dab55509e4732d39c",
            "96e65fc0784447adb1e790243b117f28",
            "96ef69fcd1764eebbab258fbc935d946",
            "d86badfd65fb430eb9b10c989d405009",
            "ab80bcedd33244b199b097e50c12dba2",
            "ece66df560c74187aaa1b7c83c3d3aae",
            "7fdfdc800f7140f0b78a766b75efce20",
            "51062909e5d04324ba90218f187166df",
            "8922ef267ea64a268cf690ffd2b81fd6",
            "c76d4612474a42888c3f306cc37f2524",
            "74593fb4e3cd4770a6752c663bea8b1f",
            "c85f44c2e6334729a3d90ede8dae1454",
            "b9d342e1b2f34b3dade065fded4c6b2a",
            "5ec67f675ee0415d9b18cd58e4d1bed4",
            "ee900b3c59f64c2eb3385acf8f246631",
            "12c0c0029ca44007b15e563f45a0e84c",
            "9889dedacc5647caa74f201ea3535562",
            "70fcf0be6aa243d79c1f25df3be2efe9",
            "b0ccc27fcd3f4c2bb4ad17f75d4d0223",
            "f3b8867578554294a49dce346cabc985",
            "af35da37901a456d9088928af7f8b6eb",
            "e1623fff489e429eb4c3531cb920593c",
            "1ea59b2cb0414d7094546a95b3f78d4d",
            "d6e7f3f50e184fbdb40a562522a09081",
            "47bf5bd806de408d98bb0a8f30ec0f93",
            "27fd9f1a21264bb1bd169a36ed0f87fd",
            "b0c44d249e654ffd89dc73384fb9127e",
            "dbf83f179ea34bc8ae342d8cb5bee23d",
            "c88368e84c064854902e6763920bb80e",
            "d645dee249064cb59824add2d6998052",
            "bc256676094544fe8ba9f52160f66964",
            "59061c7e13a74816a3cd10c1e6e8d397",
            "1b43ee4d14674455ac841f54917960c9",
            "3674d7db3eca4455b9852e0c925feecd",
            "0b5b63a9870c408cad5e458295fa9661",
            "906593e0175c4071a5b8fdb53b274a5c",
            "96635e1b31744e04a7ed8c89cd031a6b",
            "01931940edfe41b5985e301ecce1b04d",
            "f3c3fbd333594f659b54ba630531c579",
            "06633553b7774e8e87e6b06cf06cd16c"
          ]
        },
        "id": "GJKqlekZcUPZ",
        "outputId": "93aba025-6d8f-42ce-afea-4cad7b5b6361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/397 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e645ed0f64ce4cd194e1aa99c9dc9f44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58ab08fd15a1401a846ad787fb844f63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51062909e5d04324ba90218f187166df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0ccc27fcd3f4c2bb4ad17f75d4d0223"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "No LoRA keys associated to CLIPTextModelWithProjection found with the prefix='text_encoder'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModelWithProjection related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n",
            "No LoRA keys associated to CLIPTextModelWithProjection found with the prefix='text_encoder_2'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModelWithProjection related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resizing control image from (1152, 1024) to (1472, 1024)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d645dee249064cb59824add2d6998052"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated image saved to: generated_traffic_images/generated_traffic.png\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------------\n",
        "# 🎯 Inference Pipeline for SD3 + ControlNet + LoRA\n",
        "#\n",
        "# This cell demonstrates the full generation process:\n",
        "#  - Loads Stable Diffusion 3 Medium base model\n",
        "#  - Loads ControlNet (Canny edge-based guidance)\n",
        "#  - Loads LoRA weights fine-tuned on pixelated network traffic\n",
        "#  - Applies edge-conditioned generation using a sample input\n",
        "#\n",
        "# -----------------------------------------------------------\n",
        "# flush()\n",
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from diffusers import StableDiffusion3ControlNetPipeline, SD3ControlNetModel\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "# Make sure our output folder exists\n",
        "os.makedirs(\"generated_traffic_images\", exist_ok=True)\n",
        "\n",
        "# Base SD 3.0 model\n",
        "base_model_path = \"stabilityai/stable-diffusion-3-medium-diffusers\"\n",
        "\n",
        "# Canny-based ControlNet\n",
        "controlnet_path = \"InstantX/SD3-Controlnet-Canny\"\n",
        "\n",
        "# Load the ControlNet and pipeline\n",
        "controlnet = SD3ControlNetModel.from_pretrained(\n",
        "    controlnet_path, torch_dtype=torch.float16\n",
        ")\n",
        "pipe = StableDiffusion3ControlNetPipeline.from_pretrained(\n",
        "    base_model_path,\n",
        "    controlnet=controlnet,\n",
        ")\n",
        "\n",
        "# Load LoRA weights\n",
        "lora_output_path = \"trained-sd3-lora-miniature\"\n",
        "pipe.load_lora_weights(lora_output_path)\n",
        "\n",
        "# Move pipeline to GPU (half precision)\n",
        "pipe.to(\"cuda\", torch.float16)\n",
        "pipe.enable_sequential_cpu_offload()\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1) Convert original control image to Canny edges via OpenCV\n",
        "# ----------------------------------------------------\n",
        "orig_path = \"./conditioning.png\" #\"./scripts/traffic_conditioning_image.png\"\n",
        "orig_bgr = cv2.imread(orig_path)\n",
        "\n",
        "if orig_bgr is None:\n",
        "    raise ValueError(f\"Could not load file: {orig_path}\")\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(orig_bgr, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Generate Canny edge map (tweak thresholds as needed)\n",
        "edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "# Convert single-channel edge map to 3-channel RGB\n",
        "edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "# Convert to PIL for use in ControlNet pipeline\n",
        "control_image = Image.fromarray(edges_rgb)\n",
        "orig_width, orig_height = control_image.size\n",
        "\n",
        "# Determine target dimensions that are multiples of 64\n",
        "target_height = 1024 # 128 * 8\n",
        "target_width = 1472\n",
        "\n",
        "\n",
        "if orig_width != target_width or orig_height != target_height:\n",
        "    print(f\"Resizing control image from ({orig_width}, {orig_height}) to ({target_width}, {target_height})\")\n",
        "    control_image = control_image.resize((target_width, target_height))\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 3) Set up prompts and run pipeline\n",
        "# ----------------------------------------------------\n",
        "prompt = \"pixelated network data for type-0 application traffic\"\n",
        "generator = torch.manual_seed(0)  # reproducibility\n",
        "\n",
        "# Generate at 1024x1472 to match the new control image and model requirements\n",
        "image = pipe(\n",
        "    prompt=prompt,\n",
        "    num_inference_steps=20,\n",
        "    generator=generator,\n",
        "    height=target_height,\n",
        "    width=target_width,\n",
        "    control_image=control_image,\n",
        "    controlnet_conditioning_scale=0.8,  # increase to adhere more strongly to edges\n",
        ").images[0]\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 4) Save the generated image\n",
        "# ----------------------------------------------------\n",
        "output_path = os.path.join(\"generated_traffic_images\", \"generated_traffic.png\")\n",
        "image.save(output_path)\n",
        "print(f\"Generated image saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Add 64 payload_bit columns (payload_bit_0 through payload_bit_63)\n",
        "with all values set to 0 to the nprint file\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "\n",
        "def add_payload_columns(input_path, output_path, num_payload_bits=64):\n",
        "    \"\"\"\n",
        "    Add payload_bit_0 through payload_bit_{num_payload_bits-1} columns\n",
        "    with all values set to 0.\n",
        "\n",
        "    Args:\n",
        "        input_path: Path to input nprint file\n",
        "        output_path: Path to save output file with payload columns\n",
        "        num_payload_bits: Number of payload bit columns to add (default: 64)\n",
        "    \"\"\"\n",
        "    print(f\"Loading {input_path}...\")\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    original_cols = len(df.columns)\n",
        "    original_rows = len(df)\n",
        "    print(f\"  Original: {original_rows} rows × {original_cols} columns\")\n",
        "\n",
        "    # Create payload column names\n",
        "    payload_cols = [f'payload_bit_{i}' for i in range(num_payload_bits)]\n",
        "\n",
        "    # Add each payload column with all zeros\n",
        "    for col in payload_cols:\n",
        "        df[col] = 0\n",
        "\n",
        "    # Save to output\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "    new_cols = len(df.columns)\n",
        "    print(f\"  ✓ Added {num_payload_bits} payload columns\")\n",
        "    print(f\"  New: {original_rows} rows × {new_cols} columns\")\n",
        "    print(f\"  ✓ Saved to {output_path}\")\n",
        "\n",
        "    # Show the last few column names to verify\n",
        "    print(f\"\\n  Last 5 columns: {list(df.columns[-5:])}\")\n",
        "\n",
        "# Usage example\n",
        "add_payload_columns(\n",
        "    input_path=\"./scripts/correct_format.nprint\",\n",
        "    output_path=\"./scripts/correct_format.nprint\",\n",
        "    num_payload_bits=64\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3yB5V6cXDBc",
        "outputId": "a16252fa-e489-4489-f1ce-b820bfcd75ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ./scripts/correct_format.nprint...\n",
            "  Original: 1024 rows × 1409 columns\n",
            "  ✓ Added 64 payload columns\n",
            "  New: 1024 rows × 1473 columns\n",
            "  ✓ Saved to ./scripts/correct_format.nprint\n",
            "\n",
            "  Last 5 columns: ['payload_bit_59', 'payload_bit_60', 'payload_bit_61', 'payload_bit_62', 'payload_bit_63']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Remove src_ip and save it separately for reconstruction,\n",
        "then save the processed file WITH index\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "\n",
        "def remove_src_ip_with_save(input_path, output_path, src_ip_save_path):\n",
        "    \"\"\"\n",
        "    Remove src_ip, save it separately, and save remaining data with index.\n",
        "    \"\"\"\n",
        "    print(f\"Loading {input_path}...\")\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    original_cols = len(df.columns)\n",
        "    print(f\"  Original columns: {original_cols}, Rows: {len(df)}\")\n",
        "\n",
        "    # Save src_ip data\n",
        "    if 'src_ip' in df.columns:\n",
        "        src_ip_df = df[['src_ip']].copy()\n",
        "        src_ip_df.to_csv(src_ip_save_path, index=True)\n",
        "        print(f\"  ✓ Saved src_ip to {src_ip_save_path}\")\n",
        "\n",
        "        df = df.drop(columns=['src_ip'])\n",
        "        print(f\"  ✓ Removed 'src_ip' column\")\n",
        "\n",
        "    # Save WITH index=True (adds row numbers as first column)\n",
        "    df.to_csv(output_path, index=True)\n",
        "\n",
        "    print(f\"  New data columns: {len(df.columns)}\")\n",
        "    print(f\"  Total columns in file (with index): {len(df.columns) + 1}\")\n",
        "    print(f\"  Saved to {output_path}\\n\")\n",
        "\n",
        "# Usage\n",
        "remove_src_ip_with_save(\n",
        "    input_path=\"./nprint_traffic/modbus.nprint\",\n",
        "    output_path=\"./scripts/column_example.nprint\",\n",
        "    src_ip_save_path=\"./scripts/saved_src_ip_reference.csv\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V12HrYEIX1-d",
        "outputId": "516263fc-e6f4-4bb7-93b1-5b97b25a0642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ./nprint_traffic/modbus.nprint...\n",
            "  Original columns: 1473, Rows: 1024\n",
            "  ✓ Saved src_ip to ./scripts/saved_src_ip_reference.csv\n",
            "  ✓ Removed 'src_ip' column\n",
            "  New data columns: 1472\n",
            "  Total columns in file (with index): 1473\n",
            "  Saved to ./scripts/column_example.nprint\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cGTvnwgcUPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae5d7f6-6b9a-4b57-a78c-0b508a71559d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1 images.\n",
            "Processing ./color_corrected_generated_traffic_images/generated_traffic.png with size 1472 x 1024\n",
            "Saved ./generated_nprint/generated_traffic.nprint\n",
            "Done! Converted 1 .png files into .nprint format.\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------------\n",
        "# 🔄 Post-Generation Processing Pipeline\n",
        "#\n",
        "# This cell performs a 3-stage transformation of the generated PNG images:\n",
        "#   1. Applies color correction for standardization.\n",
        "#   2. Converts augmented images back into nPrint-compatible feature format.\n",
        "#   3. Applies heuristic corrections and reconstructs valid PCAP files.\n",
        "#\n",
        "# ⚙️ This pipeline enables turning synthetic traffic images\n",
        "#    back into replayable network traffic for evaluation or simulation.\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# 🎨 Step 1: Color Augmentation\n",
        "# Applies standardized color shifts to improve nprint reconstruction accuracy\n",
        "!python ./scripts/color_processor.py \\\n",
        "  --input_dir=\"./generated_traffic_images\" \\\n",
        "  --output_dir=\"./color_corrected_generated_traffic_images\"\n",
        "# -----------------------------------------------------------\n",
        "# 🔁 Step 2: Image-to-nPrint Conversion\n",
        "# Converts augmented PNG images back into `.nprint` tabular format.\n",
        "#\n",
        "# Uses a reference `.nprint` file to maintain consistent structure and column order.\n",
        "# This step allows diffusion-generated visual traffic to be fed into analysis tools.\n",
        "# -----------------------------------------------------------\n",
        "!python ./scripts/image_to_nprint.py \\\n",
        "  --org_nprint ./scripts/column_example.nprint \\\n",
        "  --input_dir ./color_corrected_generated_traffic_images \\\n",
        "  --output_dir ./generated_nprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 🧠 Step 3: Heuristic Correction & PCAP Reconstruction\n",
        "#\n",
        "# This step reconstructs a valid and replayable `.pcap` file\n",
        "# from the diffusion-generated `.nprint` representation.\n",
        "# 🔍 Core Functionalities:\n",
        "# ✅ Intra-packet corrections (fixes within individual packets).\n",
        "# 🔁 Inter-packet dependency enforcement.\n",
        "# 🔧 Reconstruction:\n",
        "#   - Save the corrected `.nprint` to disk\n",
        "#   - Call `nprint -W` to convert `.nprint` into `.pcap` using external tool\n",
        "#   - Run Scapy-based checksum updates to ensure IPv4 validity\n",
        "#   - Reconvert final `.pcap` back to `.nprint` (with fixed layout) for downstream tasks\n",
        "# -----------------------------------------------------------\n",
        "!python ./scripts/mass_reconstruction.py \\\n",
        "  --input_dir ./generated_nprint \\\n",
        "  --output_pcap_dir ./replayable_generated_pcaps \\\n",
        "  --output_nprint_dir ./replayable_generated_nprints \\\n",
        "  --formatted_nprint_path ./scripts/correct_format.nprint\n",
        "# Final Pcap is stored in replayable_generated_pcaps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evBiUALKgI9f",
        "outputId": "00beaa5d-142c-4025-b0a3-f7f25ea25dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: ./generated_nprint/generated_traffic_with_src_ip.nprint -> ./replayable_generated_pcaps/generated_traffic_with_src_ip.pcap\n",
            "Running command:\n",
            "  python3 ./scripts/reconstruction.py --generated_nprint_path './generated_nprint/generated_traffic_with_src_ip.nprint' --formatted_nprint_path './scripts/correct_format.nprint' --output './replayable_generated_pcaps/generated_traffic_with_src_ip.pcap' --nprint './replayable_generated_nprints/generated_traffic_with_src_ip.nprint'\n",
            "tcp\n",
            "malloc(): invalid next size (unsorted)\n",
            "Aborted (core dumped)\n",
            "WARNING: Inconsistent linktypes detected! The resulting file might contain invalid packets.\n",
            "WARNING: Inconsistent linktypes detected! The resulting file might contain invalid packets.\n",
            "WARNING: more Inconsistent linktypes detected! The resulting file might contain invalid packets.\n",
            "Success! Created ./replayable_generated_pcaps/generated_traffic_with_src_ip.pcap and possibly updated ./replayable_generated_nprints/generated_traffic_with_src_ip.nprint.\n",
            "\n",
            "Processing: ./generated_nprint/generated_traffic.nprint -> ./replayable_generated_pcaps/generated_traffic.pcap\n",
            "Running command:\n",
            "  python3 ./scripts/reconstruction.py --generated_nprint_path './generated_nprint/generated_traffic.nprint' --formatted_nprint_path './scripts/correct_format.nprint' --output './replayable_generated_pcaps/generated_traffic.pcap' --nprint './replayable_generated_nprints/generated_traffic.nprint'\n",
            "/content/./scripts/reconstruction.py:74: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '140.181.227.220' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  generated_nprint.at[idx, 'src_ip'] = implementing_src_ip\n",
            "tcp\n",
            "malloc(): invalid next size (unsorted)\n",
            "Aborted (core dumped)\n",
            "WARNING: Inconsistent linktypes detected! The resulting file might contain invalid packets.\n",
            "WARNING: Inconsistent linktypes detected! The resulting file might contain invalid packets.\n",
            "WARNING: more Inconsistent linktypes detected! The resulting file might contain invalid packets.\n",
            "Success! Created ./replayable_generated_pcaps/generated_traffic.pcap and possibly updated ./replayable_generated_nprints/generated_traffic.nprint.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For long running jobs, copy output to Drive\n",
        "!cp -r nprint_traffic_images drive/MyDrive/SCADA_NetDiff\n",
        "!cp -r color_corrected_generated_traffic_images drive/MyDrive/SCADA_NetDiff\n",
        "!cp -r replayable_generated_pcaps drive/MyDrive/SCADA_NetDiff\n",
        "!cp -r replayable_generated_nprints drive/MyDrive/SCADA_NetDiff\n",
        "!cp -r trained-sd3-lora-miniature drive/MyDrive/SCADA_NetDiff"
      ],
      "metadata": {
        "id": "ZXQ5FAcbwkLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf68931-329e-4e13-eec6-49ac588932b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create directory 'drive/MyDrive/SCADA_NetDiff': No such file or directory\n",
            "cp: cannot create directory 'drive/MyDrive/SCADA_NetDiff': No such file or directory\n",
            "cp: cannot create directory 'drive/MyDrive/SCADA_NetDiff': No such file or directory\n",
            "cp: cannot create directory 'drive/MyDrive/SCADA_NetDiff': No such file or directory\n",
            "cp: cannot create directory 'drive/MyDrive/SCADA_NetDiff': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KuwFJRGJEfNy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e645ed0f64ce4cd194e1aa99c9dc9f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18ad26219a884a10907170d150171ec6",
              "IPY_MODEL_ef5cb42c1b4c452d8d7c6392f80e0659",
              "IPY_MODEL_eeb58e8bd4c84318882608c564db9e61"
            ],
            "layout": "IPY_MODEL_32d4cccf904748b1874039e2c959f420"
          }
        },
        "18ad26219a884a10907170d150171ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6fd56e0fda84fd8bbcf4ac026de3301",
            "placeholder": "​",
            "style": "IPY_MODEL_987bb0b30cb64601a9e0ca6be7ba0b57",
            "value": "config.json: 100%"
          }
        },
        "ef5cb42c1b4c452d8d7c6392f80e0659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa474b50e6c64037b95f8c131501294d",
            "max": 397,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17dee7f10adc477ab22b296993f7fd4a",
            "value": 397
          }
        },
        "eeb58e8bd4c84318882608c564db9e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19cb046ba457435fb4ef8970e49e775f",
            "placeholder": "​",
            "style": "IPY_MODEL_1e9fc414fee24446822551019a18a2eb",
            "value": " 397/397 [00:00&lt;00:00, 49.9kB/s]"
          }
        },
        "32d4cccf904748b1874039e2c959f420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6fd56e0fda84fd8bbcf4ac026de3301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "987bb0b30cb64601a9e0ca6be7ba0b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa474b50e6c64037b95f8c131501294d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17dee7f10adc477ab22b296993f7fd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19cb046ba457435fb4ef8970e49e775f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9fc414fee24446822551019a18a2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58ab08fd15a1401a846ad787fb844f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7227ceb428f2441a8150aea8809f9961",
              "IPY_MODEL_ce4d89b028a346948249d62c84076e8b",
              "IPY_MODEL_15e8a274884742079171fbc037042401"
            ],
            "layout": "IPY_MODEL_d74f542ae52f4b7dab55509e4732d39c"
          }
        },
        "7227ceb428f2441a8150aea8809f9961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96e65fc0784447adb1e790243b117f28",
            "placeholder": "​",
            "style": "IPY_MODEL_96ef69fcd1764eebbab258fbc935d946",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "ce4d89b028a346948249d62c84076e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86badfd65fb430eb9b10c989d405009",
            "max": 1190879768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab80bcedd33244b199b097e50c12dba2",
            "value": 1190879768
          }
        },
        "15e8a274884742079171fbc037042401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece66df560c74187aaa1b7c83c3d3aae",
            "placeholder": "​",
            "style": "IPY_MODEL_7fdfdc800f7140f0b78a766b75efce20",
            "value": " 1.19G/1.19G [00:03&lt;00:00, 595MB/s]"
          }
        },
        "d74f542ae52f4b7dab55509e4732d39c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e65fc0784447adb1e790243b117f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ef69fcd1764eebbab258fbc935d946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d86badfd65fb430eb9b10c989d405009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab80bcedd33244b199b097e50c12dba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ece66df560c74187aaa1b7c83c3d3aae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fdfdc800f7140f0b78a766b75efce20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51062909e5d04324ba90218f187166df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8922ef267ea64a268cf690ffd2b81fd6",
              "IPY_MODEL_c76d4612474a42888c3f306cc37f2524",
              "IPY_MODEL_74593fb4e3cd4770a6752c663bea8b1f"
            ],
            "layout": "IPY_MODEL_c85f44c2e6334729a3d90ede8dae1454"
          }
        },
        "8922ef267ea64a268cf690ffd2b81fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9d342e1b2f34b3dade065fded4c6b2a",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec67f675ee0415d9b18cd58e4d1bed4",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "c76d4612474a42888c3f306cc37f2524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee900b3c59f64c2eb3385acf8f246631",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12c0c0029ca44007b15e563f45a0e84c",
            "value": 9
          }
        },
        "74593fb4e3cd4770a6752c663bea8b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9889dedacc5647caa74f201ea3535562",
            "placeholder": "​",
            "style": "IPY_MODEL_70fcf0be6aa243d79c1f25df3be2efe9",
            "value": " 9/9 [00:24&lt;00:00,  1.34s/it]"
          }
        },
        "c85f44c2e6334729a3d90ede8dae1454": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d342e1b2f34b3dade065fded4c6b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec67f675ee0415d9b18cd58e4d1bed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee900b3c59f64c2eb3385acf8f246631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c0c0029ca44007b15e563f45a0e84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9889dedacc5647caa74f201ea3535562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70fcf0be6aa243d79c1f25df3be2efe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0ccc27fcd3f4c2bb4ad17f75d4d0223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3b8867578554294a49dce346cabc985",
              "IPY_MODEL_af35da37901a456d9088928af7f8b6eb",
              "IPY_MODEL_e1623fff489e429eb4c3531cb920593c"
            ],
            "layout": "IPY_MODEL_1ea59b2cb0414d7094546a95b3f78d4d"
          }
        },
        "f3b8867578554294a49dce346cabc985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6e7f3f50e184fbdb40a562522a09081",
            "placeholder": "​",
            "style": "IPY_MODEL_47bf5bd806de408d98bb0a8f30ec0f93",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "af35da37901a456d9088928af7f8b6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27fd9f1a21264bb1bd169a36ed0f87fd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0c44d249e654ffd89dc73384fb9127e",
            "value": 2
          }
        },
        "e1623fff489e429eb4c3531cb920593c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf83f179ea34bc8ae342d8cb5bee23d",
            "placeholder": "​",
            "style": "IPY_MODEL_c88368e84c064854902e6763920bb80e",
            "value": " 2/2 [00:11&lt;00:00,  5.06s/it]"
          }
        },
        "1ea59b2cb0414d7094546a95b3f78d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6e7f3f50e184fbdb40a562522a09081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47bf5bd806de408d98bb0a8f30ec0f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27fd9f1a21264bb1bd169a36ed0f87fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c44d249e654ffd89dc73384fb9127e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbf83f179ea34bc8ae342d8cb5bee23d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88368e84c064854902e6763920bb80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d645dee249064cb59824add2d6998052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc256676094544fe8ba9f52160f66964",
              "IPY_MODEL_59061c7e13a74816a3cd10c1e6e8d397",
              "IPY_MODEL_1b43ee4d14674455ac841f54917960c9"
            ],
            "layout": "IPY_MODEL_3674d7db3eca4455b9852e0c925feecd"
          }
        },
        "bc256676094544fe8ba9f52160f66964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5b63a9870c408cad5e458295fa9661",
            "placeholder": "​",
            "style": "IPY_MODEL_906593e0175c4071a5b8fdb53b274a5c",
            "value": "100%"
          }
        },
        "59061c7e13a74816a3cd10c1e6e8d397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96635e1b31744e04a7ed8c89cd031a6b",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01931940edfe41b5985e301ecce1b04d",
            "value": 20
          }
        },
        "1b43ee4d14674455ac841f54917960c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c3fbd333594f659b54ba630531c579",
            "placeholder": "​",
            "style": "IPY_MODEL_06633553b7774e8e87e6b06cf06cd16c",
            "value": " 20/20 [00:51&lt;00:00,  2.58s/it]"
          }
        },
        "3674d7db3eca4455b9852e0c925feecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5b63a9870c408cad5e458295fa9661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "906593e0175c4071a5b8fdb53b274a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96635e1b31744e04a7ed8c89cd031a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01931940edfe41b5985e301ecce1b04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3c3fbd333594f659b54ba630531c579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06633553b7774e8e87e6b06cf06cd16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}